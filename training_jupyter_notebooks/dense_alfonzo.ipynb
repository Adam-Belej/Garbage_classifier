{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7044126,"sourceType":"datasetVersion","datasetId":4015979}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import typing\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n\nclass Classifier:\n\n    def __init__(self,\n                 num_of_classes: int,\n                 epochs: int = 8,\n                 batchsize: int = 128,\n                 valsplit: int = 0.1):\n        self.num_of_classes = num_of_classes\n        self.epochs = epochs\n        self.batchsize = batchsize\n        self.valsplit = valsplit\n\n\n    def load_pretrained_model(self, path: str):\n        self.model = tf.keras.models.load_model(filepath=path)\n\n\n    def export_model(self, path: str):\n        tf.keras.Model.save(self.model, filepath=path)\n\n    def train(self, training_data, validation_data):\n        history = self.model.fit(training_data,\n                                 epochs=self.epochs,\n                                 validation_data=validation_data,\n                                 shuffle=True)\n        self.history = history\n\n\n    def classify(self, data: str, height: int, width: int):\n        img = tf.keras.utils.load_img(\n            data, target_size=(height, width)\n        )\n        img_array = tf.keras.utils.img_to_array(img)\n        img_array = tf.expand_dims(img_array, 0)\n\n        predictions = self.model.predict(img_array)\n        score = tf.nn.softmax(predictions)\n\n        return score\n\n\n    def make_graph_from_history(self):\n        acc = self.history.history['accuracy']\n        val_acc = self.history.history['val_accuracy']\n        print(\"Calculating the loss\")\n        loss = self.history.history['loss']\n        val_loss = self.history.history['val_loss']\n        \n\n        epochs_range = range(self.epochs)\n        print(\"The results are being visualized\")\n        plt.figure(figsize=(8, 8))\n        plt.subplot(1, 2, 1)\n        plt.plot(epochs_range, acc, label='Training Accuracy')\n        plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n        plt.legend(loc='lower right')\n        plt.title('Training and Validation Accuracy')\n        plt.subplot(1, 2, 2)\n\n        plt.plot(epochs_range, loss, label='Training Loss')\n        plt.plot(epochs_range, val_loss, label='Validation Loss')\n        plt.legend(loc='upper right')\n        plt.title('Training and Validation Loss')\n        plt.show()\n    \n    def test_accuracy(self, test_data_dir: str,\n                      img_width: int = 512,\n                      img_height: int = 512):\n        test_ds = nu.load_dataset(data_dir=test_data_dir,\n                        img_width=img_width,\n                        img_height=img_height)\n\n        self.evaluation = self.model.evaluate(test_ds)\n    \ndef load_dataset(data_dir: str,\n                 subset: str = None,\n                 validation_split: int = 0.1,\n                 img_width: int = 512,\n                 img_height: int = 512,\n                 batch_size: int = 128,\n                 seed: int = 123):\n    image_size = (img_height, img_width)\n    if subset is not None:\n        ds = tf.keras.utils.image_dataset_from_directory(\n            directory=data_dir,\n            subset=subset,\n            validation_split=validation_split,\n            image_size=image_size,\n            batch_size=batch_size,\n            seed=seed\n        )\n\n    else:\n        ds = tf.keras.utils.image_dataset_from_directory(\n            directory=data_dir,\n            image_size=image_size,\n            batch_size=batch_size\n        )\n    return ds\n\n\ndef pretrained_model(directory: str):\n    model = tf.saved_model.load(directory)\n    return model\n\n\n\ndef predict_image(img_dir: str, img_width: int, img_height: int, model):\n    img = tf.keras.utils.load_img(path=img_dir,\n                                  target_size=(img_height, img_width))\n    model.predict(img)\n\nclass Alfonzo(Classifier):\n\n    def __init__(self,\n                 num_of_classes: int):\n        super().__init__(num_of_classes)\n        self.model = tf.keras.models.Sequential(\n            [\n                tf.keras.layers.Rescaling(1. / 255),\n                tf.keras.layers.Flatten(),\n                tf.keras.layers.Dense(units=128, activation='relu'),\n                tf.keras.layers.Dense(units=64, activation='relu'),\n                tf.keras.layers.Dense(units=32, activation='relu'),\n                tf.keras.layers.Dense(units=16, activation='relu'),\n                tf.keras.layers.Dense(units=num_of_classes)\n            ])\n        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n                           loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                           metrics=\"accuracy\"),\n\n\nalfonz = Alfonzo(3)\n\ntraining_set = load_dataset(data_dir='/kaggle/input/odpadky/dataset/train',\n                            img_width=512,\n                            img_height=512,\n                            subset=\"training\",\n                            validation_split=alfonz.valsplit,\n                            seed=123,\n                            batch_size=alfonz.batchsize)\nvalidation_set = load_dataset(data_dir='/kaggle/input/odpadky/dataset/train',\n                             img_width=512,\n                             img_height=512,\n                             subset=\"validation\",\n                             validation_split=alfonz.valsplit,\n                             seed=123,\n                             batch_size=alfonz.batchsize)\nalfonz.model.build(input_shape=(1, 512, 512, 3))\nalfonz.model.summary()\nalfonz.train(training_data=training_set,\n             validation_data=validation_set)\n\nprint(\"History is \", alfonz.history)\n\nalfonz.make_graph_from_history()\n\ntest_ds = load_dataset(data_dir='/kaggle/input/odpadky/dataset/test',\n                        img_width=512,\n                        img_height=512)\n\nalfonz.evaluation = alfonz.model.evaluate(test_ds)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-24T21:43:32.797426Z","iopub.execute_input":"2023-11-24T21:43:32.797761Z","iopub.status.idle":"2023-11-24T22:16:38.672089Z","shell.execute_reply.started":"2023-11-24T21:43:32.797734Z","shell.execute_reply":"2023-11-24T22:16:38.665541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}